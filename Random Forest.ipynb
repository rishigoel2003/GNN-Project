{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rishi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hierarchicalforecast\\methods.py:261: RuntimeWarning: invalid value encountered in divide\n",
      "  reconciled[idx_child] = y_hat[idx_child] * fcst_parent / childs_sum\n",
      "c:\\Users\\Rishi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hierarchicalforecast\\methods.py:261: RuntimeWarning: invalid value encountered in divide\n",
      "  reconciled[idx_child] = y_hat[idx_child] * fcst_parent / childs_sum\n",
      "c:\\Users\\Rishi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hierarchicalforecast\\methods.py:261: RuntimeWarning: invalid value encountered in divide\n",
      "  reconciled[idx_child] = y_hat[idx_child] * fcst_parent / childs_sum\n",
      "c:\\Users\\Rishi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hierarchicalforecast\\methods.py:261: RuntimeWarning: invalid value encountered in divide\n",
      "  reconciled[idx_child] = y_hat[idx_child] * fcst_parent / childs_sum\n",
      "c:\\Users\\Rishi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hierarchicalforecast\\methods.py:261: RuntimeWarning: invalid value encountered in divide\n",
      "  reconciled[idx_child] = y_hat[idx_child] * fcst_parent / childs_sum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE for RF/MinTrace_method-ols\n",
      "Country MASE: 0.7729599826761856\n",
      "Country/State MASE: 0.7829253982595344\n",
      "Country/State/Store MASE: 0.9066474072998554\n",
      "\n",
      "MASE for RF/TopDown_method-forecast_proportions\n",
      "Country MASE: 0.808833890649213\n",
      "Country/State MASE: nan\n",
      "Country/State/Store MASE: nan\n",
      "\n",
      "MASE for RF/BottomUp\n",
      "Country MASE: 0.7686367889216583\n",
      "Country/State MASE: 0.7850322905777448\n",
      "Country/State/Store MASE: 0.8818490092095571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import  BottomUp, TopDown, MinTrace\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "\n",
    "callbacks = [lgb.log_evaluation(period=0)]\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "sales_train_eval = pd.read_csv('sales_train_evaluation.csv')\n",
    "sell_price = pd.read_csv('sell_prices.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "\n",
    "foods = pd.read_csv('List_of_foods.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#making the summing matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rows / columns\n",
    "list1 = ['Total', 'CA','CA_1','CA_2','CA_3','CA_4','TX','TX_1','TX_2','TX_3','WI','WI_1','WI_2','WI_3']\n",
    "list2 = ['CA_1','CA_2','CA_3','CA_4','TX_1','TX_2','TX_3','WI_1','WI_2','WI_3']\n",
    "S = np.zeros((len(list1), len(list2)))\n",
    "\n",
    "S = pd.DataFrame(S); S.index = list1; S.columns = list2\n",
    "\n",
    "\n",
    "# encode the hierarchical structure\n",
    "S.loc['Total'] = 1\n",
    "S.loc['CA'][['CA_1','CA_2','CA_3', 'CA_4']] = 1\n",
    "S.loc['TX'][['TX_1','TX_2','TX_3']] = 1\n",
    "S.loc['WI'][['WI_1','WI_2','WI_3']] = 1\n",
    "for x in S.columns:\n",
    "    S.loc[x][x]= 1\n",
    "S = S.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tags = {}\n",
    "tags['Country'] = np.array(['Total'], dtype=object)\n",
    "tags['Country/State'] = np.array(['CA', 'TX', 'WI'], dtype=object)\n",
    "tags['Country/State/Store'] = np.array(['CA_1', 'CA_2', 'CA_3', 'CA_4',  \n",
    "                                        'TX_1', 'TX_2', 'TX_3',\n",
    "                                        'WI_1', 'WI_2', 'WI_3'], dtype=object)\n",
    "\n",
    "\n",
    "\n",
    "horizon = 28\n",
    "\n",
    "\n",
    "\n",
    "def label_encoding(train, feature):\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(train[feature].values.astype(str))\n",
    "    train[feature] = encoder.fit_transform(train[feature].values.astype(str))\n",
    "    \n",
    "    return train[feature]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "col = ['event_name_1', 'event_type_1',\n",
    "       'event_name_2', 'event_type_2', 'wday','month', 'year', 'value_lag_1', 'value_lag_2', \n",
    "       'value_lag_3', 'value_lag_6', 'value_lag_12', 'value_lag_24', 'value_lag_36', 'rolling_value_mean']\n",
    "\n",
    "\n",
    "# hyperparameters = {\n",
    "#     'boosting_type': ['rf'],\n",
    "#     'metric': ['rmse'],\n",
    "#     'objective': ['regression'],\n",
    "#     'n_jobs': [-1],\n",
    "#     #'seed': [236],\n",
    "#     'learning_rate': [0.28],\n",
    "#     'bagging_fraction': [0.75],\n",
    "#     'bagging_freq': [5],\n",
    "#     'colsample_bytree': [0.75],\n",
    "#     'force_row_wise' : [True],\n",
    "#     'verbose':[-1],\n",
    "#     'num_leaves':[63]\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "def MASE(y_true, y_pred, y_train):\n",
    "    e_t = y_true - y_pred\n",
    "    scale = mean_absolute_error(y_train[1:], y_train[:-1])\n",
    "    return np.mean(np.abs(e_t / scale))\n",
    "\n",
    "\n",
    "n=10\n",
    "\n",
    "\n",
    "\n",
    "MASE_errors_average = [0] * 9\n",
    "\n",
    "average_rmse = 0\n",
    "\n",
    "\n",
    "for food_num in range(n):\n",
    "\n",
    "    product_id = foods.loc[food_num].at[\"Foods\"]\n",
    "\n",
    "\n",
    "    product_data = sales_train_eval[sales_train_eval['item_id'].str.contains(product_id)]\n",
    "    product_sell_price = sell_price[sell_price['item_id'].str.contains(product_id)]\n",
    "\n",
    "\n",
    "    df = pd.melt(\n",
    "    product_data,\n",
    "    id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "    var_name='d',\n",
    "    value_name='value').dropna()\n",
    "    df = pd.merge(df, calendar, on='d', how='left')\n",
    "\n",
    "    df = df[(df['date'] > '2012-01-01')]\n",
    "\n",
    "    df[\"event_name_1\"] = df[\"event_name_1\"].fillna(\"no_event\")\n",
    "    df[\"event_name_2\"] = df[\"event_name_2\"].fillna(\"no_event\")\n",
    "    df[\"event_type_1\"] = df[\"event_type_1\"].fillna(\"no_event\")\n",
    "    df[\"event_type_2\"] = df[\"event_type_2\"].fillna(\"no_event\")\n",
    "\n",
    "\n",
    "\n",
    "    df_stores = df.groupby(['date', 'store_id','wday','month','year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'])[['value']].sum()\n",
    "    df_stores.reset_index(inplace=True)\n",
    "    df_stores = df_stores.T.reset_index(drop=True).T\n",
    "    df_stores.columns = ['d', 'unique_id', 'wday','month','year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2','sales']\n",
    "\n",
    "\n",
    "    df_state = df.groupby(['date', 'state_id','wday','month','year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'])[['value']].sum()\n",
    "    df_state.reset_index(inplace=True)\n",
    "    df_state = df_state.T.reset_index(drop=True).T\n",
    "    df_state.columns = ['d', 'unique_id','wday','month','year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'sales']\n",
    "\n",
    "\n",
    "\n",
    "    df_total = df.groupby(['date','wday','month','year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'])[['value']].sum()\n",
    "    df_total.reset_index(inplace=True)\n",
    "    df_total['unique_id'] = 'Total'\n",
    "    df_total.columns = ['d','wday','month','year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2','sales', 'unique_id']\n",
    "\n",
    "    df_all = pd.concat([df_stores, df_state, df_total], axis = 0)\n",
    "\n",
    "    df_all.columns = ['ds','unique_id','wday','month','year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'y']\n",
    "    df_all['ds'] = pd.to_datetime(df_all['ds'])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #Introduce lags\n",
    "    lags = [1,2,3,6,12,24,36]\n",
    "    for lag in lags:\n",
    "        df_all['value_lag_'+str(lag)] = df_all.groupby(['unique_id'],as_index=False)['y'].shift(lag)\n",
    "\n",
    "    for lag in lags:\n",
    "        df_all['value_lag_'+str(lag)] = df_all['value_lag_'+str(lag)].fillna(0)\n",
    "\n",
    "    df_all['rolling_value_mean'] = df_all.groupby(['unique_id'])['y'].transform(lambda x: x.rolling(window=7).mean()).astype(np.float16)\n",
    "    df_all['rolling_value_mean'] = df_all['rolling_value_mean'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_all['wday']  = label_encoding(df_all,\"wday\" )\n",
    "    df_all['month']  = label_encoding(df_all,\"month\" )\n",
    "    df_all['year']  = label_encoding(df_all,\"year\" )\n",
    "\n",
    "    df_all['event_name_1']  = label_encoding(df_all,\"event_name_1\" )\n",
    "    df_all['event_name_2']  = label_encoding(df_all,\"event_name_2\" )\n",
    "    df_all['event_type_1']  = label_encoding(df_all,\"event_type_1\" )\n",
    "    df_all['event_type_2']  = label_encoding(df_all,\"event_type_2\" )\n",
    "\n",
    "\n",
    "\n",
    "    x_test = df_all.groupby('unique_id').tail(horizon)\n",
    "    x_train = df_all.drop(x_test.index)\n",
    "    x_val = x_train.groupby('unique_id').tail(horizon)\n",
    "    x_train = x_train.drop(x_val.index)\n",
    "\n",
    "\n",
    "    x_train['y'] = x_train['y'].astype(float)\n",
    "    x_test['y'] = x_test['y'].astype(float)\n",
    "    x_val['y'] = x_val['y'].astype(float)\n",
    "\n",
    "\n",
    "    y_train = x_train['y']\n",
    "    y_test = x_test['y']\n",
    "    y_val = x_val['y']\n",
    "\n",
    "\n",
    "\n",
    "    # train_set = lgb.Dataset(x_train[col], y_train)\n",
    "\n",
    "    # model = lgb.train(hyperparameters, train_set, num_boost_round = 400)\n",
    "    # val_pred = model.predict(x_val[col])\n",
    "    # val_score = mean_squared_error(val_pred, y_val)\n",
    "    # average_rmse += val_score    \n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(x_train[col], y_train)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    x_hat = model.predict(x_test[col])\n",
    "\n",
    "\n",
    "    x_hat = pd.DataFrame(x_hat,columns = ['RF'])\n",
    "\n",
    "\n",
    "    x_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "    x_hat['unique_id'] = x_test['unique_id']\n",
    "\n",
    "\n",
    "    x_hat['ds'] = x_test['ds']\n",
    "\n",
    "    x_test = x_test.set_index('unique_id')\n",
    "    x_train = x_train.set_index('unique_id')\n",
    "    x_val = x_val.set_index('unique_id')\n",
    "    x_hat2 = x_hat.set_index('unique_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    reconcilers = [\n",
    "        MinTrace(method='ols'),\n",
    "        TopDown(method='forecast_proportions'),\n",
    "        BottomUp()\n",
    "    ]\n",
    "\n",
    "    hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "\n",
    "    x_hat_rec = hrec.reconcile(x_hat2, S, tags)\n",
    "\n",
    "\n",
    "\n",
    "    methods = ['RF/MinTrace_method-ols','RF/TopDown_method-forecast_proportions','RF/BottomUp']\n",
    "    nm=len(methods)\n",
    "\n",
    "    errors = [0] * 9\n",
    "\n",
    "    counter = 0\n",
    "    for i in range(nm):\n",
    "\n",
    "        rightdf = x_hat_rec[[\"ds\",methods[i]]]\n",
    "        leftdf = x_test[[\"ds\",\"y\"]]\n",
    "        xmat = pd.merge(left = leftdf, right = rightdf, on = ['ds', 'unique_id'])\n",
    "        xmat.columns = [['ds', 'y', 'pred']]\n",
    "\n",
    "        #print(xmat.loc[tags['Country'],'pred'])\n",
    "\n",
    "\n",
    "        \n",
    "        for k in tags.keys():\n",
    "            errors[counter] = MASE(xmat.loc[tags[k],'y'].to_numpy(), xmat.loc[tags[k],'pred'].to_numpy(), x_train.loc[tags[k],'y'].to_numpy())\n",
    "            counter += 1\n",
    "            \n",
    "\n",
    "    MASE_errors_average = np.array(MASE_errors_average) + np.array(errors)  \n",
    "\n",
    "\n",
    "\n",
    "MASE_errors_average = MASE_errors_average/n\n",
    "   \n",
    "\n",
    "count=0\n",
    "for i in range(nm):\n",
    "    print('MASE for ' + methods[i])\n",
    "    for k in tags.keys():\n",
    "        print(k + ' MASE: ' + str(MASE_errors_average[count]))\n",
    "        count += 1\n",
    "    print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
