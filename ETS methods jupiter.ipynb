{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE for AutoETS/MinTrace_method-ols\n",
      "Country MASE: 0.48465810432292\n",
      "Country/State MASE: 0.6372108611490623\n",
      "Country/State/Store MASE: 0.8103811659752402\n",
      "\n",
      "MASE for AutoETS/TopDown_method-forecast_proportions\n",
      "Country MASE: 0.47959476296731746\n",
      "Country/State MASE: 0.650941928889983\n",
      "Country/State/Store MASE: 0.80989158924257\n",
      "\n",
      "MASE for AutoETS/BottomUp\n",
      "Country MASE: 0.5329773653878881\n",
      "Country/State MASE: 0.6460303340254733\n",
      "Country/State/Store MASE: 0.8096337104851911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import  BottomUp, TopDown, MinTrace\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import AutoETS\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "sales_train_eval = pd.read_csv('sales_train_evaluation.csv')\n",
    "sell_price = pd.read_csv('sell_prices.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "\n",
    "foods = pd.read_csv('List_of_foods.csv')\n",
    "n=5\n",
    "\n",
    "\n",
    "\n",
    "MASE_errors_average = [0] * 9\n",
    "\n",
    "for food_num in range(n):\n",
    "    product_id = foods.loc[food_num].at[\"Foods\"]\n",
    "\n",
    "\n",
    "    product_data = sales_train_eval[sales_train_eval['item_id'].str.contains(product_id)]\n",
    "    product_sell_price = sell_price[sell_price['item_id'].str.contains(product_id)]\n",
    "\n",
    "\n",
    "    df = pd.melt(\n",
    "        product_data,\n",
    "        id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "        var_name='d',\n",
    "        value_name='value').dropna()\n",
    "    df = pd.merge(df, calendar, on='d', how='left')\n",
    "\n",
    "\n",
    "    df = df[(df['date'] > '2016-01-01')]\n",
    "\n",
    "\n",
    "\n",
    "    df_stores = df.groupby(['date', 'store_id'])[['value']].sum()\n",
    "    df_stores.reset_index(inplace=True)\n",
    "    df_stores = df_stores.T.reset_index(drop=True).T\n",
    "    df_stores.columns = ['d', 'unique_id', 'sales']\n",
    "\n",
    "\n",
    "    df_state = df.groupby(['date', 'state_id'])[['value']].sum()\n",
    "    df_state.reset_index(inplace=True)\n",
    "    df_state = df_state.T.reset_index(drop=True).T\n",
    "    df_state.columns = ['d', 'unique_id', 'sales']\n",
    "\n",
    "\n",
    "    df_total = df.groupby(['date'])[['value']].sum()\n",
    "    df_total.reset_index(inplace=True)\n",
    "    df_total['unique_id'] = 'Total'\n",
    "    df_total.columns = ['d','sales', 'unique_id']\n",
    "\n",
    "    df_all = pd.concat([df_stores, df_state, df_total], axis = 0)\n",
    "\n",
    "    xset = set(df_all.unique_id)\n",
    "    df_all.columns = ['ds', 'unique_id', 'y']\n",
    "    df_all['ds'] = pd.to_datetime(df_all['ds'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #making the summing matrix\n",
    "\n",
    "    S = np.zeros((len(xset), len([f for f in xset if '_' in f])))\n",
    "\n",
    "\n",
    "    # rows / columns\n",
    "    list1 = ['Total', 'CA','CA_1','CA_2','CA_3','CA_4','TX','TX_1','TX_2','TX_3','WI','WI_1','WI_2','WI_3']\n",
    "    list2 = ['CA_1','CA_2','CA_3','CA_4','TX_1','TX_2','TX_3','WI_1','WI_2','WI_3']\n",
    "    S = pd.DataFrame(S); S.index = list1; S.columns = list2\n",
    "\n",
    "\n",
    "    # encode the hierarchical structure\n",
    "    S.loc['Total'] = 1\n",
    "    S.loc['CA'][['CA_1','CA_2','CA_3', 'CA_4']] = 1\n",
    "    S.loc['TX'][['TX_1','TX_2','TX_3']] = 1\n",
    "    S.loc['WI'][['WI_1','WI_2','WI_3']] = 1\n",
    "    for x in S.columns:\n",
    "        S.loc[x][x]= 1\n",
    "    S = S.astype(int)\n",
    "    S\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tags = {}\n",
    "    tags['Country'] = np.array(['Total'], dtype=object)\n",
    "    tags['Country/State'] = np.array(['CA', 'TX', 'WI'], dtype=object)\n",
    "    tags['Country/State/Store'] = np.array(['CA_1', 'CA_2', 'CA_3', 'CA_4',  \n",
    "                                            'TX_1', 'TX_2', 'TX_3',\n",
    "                                            'WI_1', 'WI_2', 'WI_3'], dtype=object)\n",
    "    tags\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    horizon = 28\n",
    "\n",
    "\n",
    "\n",
    "    x_test = df_all.groupby('unique_id').tail(horizon)\n",
    "    x_train = df_all.drop(x_test.index)\n",
    "    x_test = x_test.set_index('unique_id')\n",
    "    x_train = x_train.set_index('unique_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fcst = StatsForecast(df = x_train, models=[AutoETS(season_length= 7, model ='AAA', damped = True)], freq='D', n_jobs=-1)\n",
    "    x_hat = fcst.forecast(h = horizon)\n",
    "\n",
    "\n",
    "\n",
    "    def MASE(y_true, y_pred, y_train):\n",
    "        e_t = y_true - y_pred\n",
    "        scale = mean_absolute_error(y_train[1:], y_train[:-1])\n",
    "        return np.mean(np.abs(e_t / scale))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    reconcilers = [\n",
    "        MinTrace(method='ols'),\n",
    "        TopDown(method='forecast_proportions'),\n",
    "        BottomUp()\n",
    "    ]\n",
    "\n",
    "    hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "\n",
    "    x_hat_rec = hrec.reconcile(x_hat, S, tags)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #methods = ['ETS/MinTrace_method-ols','ETS/TopDown_method-forecast_proportions','ETS/BottomUp']\n",
    "    methods = ['AutoETS/MinTrace_method-ols','AutoETS/TopDown_method-forecast_proportions','AutoETS/BottomUp']\n",
    "    \n",
    "    nm=len(methods)\n",
    "\n",
    "    errors = [0] * 9\n",
    "\n",
    "    counter = 0\n",
    "    for i in range(nm):\n",
    "\n",
    "        rightdf = x_hat_rec[[\"ds\",methods[i]]]\n",
    "        xmat = pd.merge(left = x_test, right = rightdf, on = ['ds', 'unique_id'])\n",
    "        xmat.columns = [['ds', 'y', 'pred']]\n",
    "\n",
    "        \n",
    "        for k in tags.keys():\n",
    "            errors[counter] = MASE(xmat.loc[tags[k]]['y'].to_numpy(), xmat.loc[tags[k]]['pred'].to_numpy(), x_train.loc[tags[k]]['y'].to_numpy())\n",
    "            counter += 1\n",
    "\n",
    "    \n",
    "    MASE_errors_average = np.array(MASE_errors_average) + np.array(errors)  \n",
    "\n",
    "\n",
    "MASE_errors_average = MASE_errors_average/5\n",
    "\n",
    "\n",
    "count=0\n",
    "for i in range(nm):\n",
    "    print('MASE for ' + methods[i])\n",
    "    for k in tags.keys():\n",
    "        print(k + ' MASE: ' + str(MASE_errors_average[count]))\n",
    "        count += 1\n",
    "    print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
